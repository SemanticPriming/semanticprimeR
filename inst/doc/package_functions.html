<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Erin Buchanan" />

<meta name="date" content="2024-11-10" />

<title>semanticprimeR Package Functions</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">semanticprimeR Package Functions</h1>
<h4 class="author">Erin Buchanan</h4>
<h4 class="date">2024-11-10</h4>



<div id="libraries" class="section level2">
<h2>Libraries</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(semanticprimeR)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="fu">library</span>(udpipe)</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="fu">library</span>(stopwords)</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="fu">library</span>(tibble)</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="fu">library</span>(rio)</span></code></pre></div>
</div>
<div id="power-functions" class="section level2">
<h2>Power Functions</h2>
<p>During the process of this project, we proposed a new way to
calculate “power” for adaptive sampling of items using accuracy in
parameter estimation and bootstrapping/simulation methods. You can
review the preprint here: <a href="https://osf.io/preprints/osf/e3afx" class="uri">https://osf.io/preprints/osf/e3afx</a></p>
<p>This package has many vignettes for different types of data you can
examine by using <code>vignette(package = &quot;semanticprimeR&quot;)</code> to
review what is available and
<code>vignette(topic = &quot;montefinese_vignette&quot;, package = &quot;semanticprimeR&quot;)</code>
as a specific example to view a specific vignette.</p>
<p>The information presented here is a shortened version of the paper to
show off the functionality of the package.</p>
<div id="simulate-population" class="section level3">
<h3>Simulate Population</h3>
<p>Let’s say we want to run a priming study, but do not have previous
data. We can use <code>simulate_population()</code> to create some
sample data to use in for estimating sample size for adaptive testing
and stopping rules.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">simulate_population</span>(<span class="at">mu =</span> <span class="dv">25</span>, <span class="co"># mean priming in ms</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>                    <span class="at">mu_sigma =</span> <span class="dv">5</span>, <span class="co"># standard deviation of the item means</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>                    <span class="at">sigma =</span> <span class="dv">10</span>, <span class="co"># population standard deviation for items</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>                    <span class="at">sigma_sigma =</span> <span class="dv">3</span>, <span class="co"># standard deviation of the standard deviation of items</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>                    <span class="at">number_items =</span> <span class="dv">75</span>, <span class="co"># number of priming items </span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>                    <span class="at">number_scores =</span> <span class="dv">100</span>, <span class="co"># a population of values to simulate</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>                    <span class="at">smallest_sigma =</span> <span class="dv">1</span>, <span class="co"># smallest possible item standard deviation </span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>                    <span class="at">min_score =</span> <span class="sc">-</span><span class="dv">25</span>, <span class="co"># min ms priming</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>                    <span class="at">max_score =</span> <span class="dv">100</span>, <span class="co"># max ms priming </span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>                    <span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="fu">head</span>(df)</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="co">#&gt;   item  score</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a><span class="co">#&gt; 1    1 24.727</span></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a><span class="co">#&gt; 2    2 40.868</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a><span class="co">#&gt; 3    3 32.125</span></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a><span class="co">#&gt; 4    4  7.695</span></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a><span class="co">#&gt; 5    5  6.408</span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a><span class="co">#&gt; 6    6 28.881</span></span></code></pre></div>
</div>
<div id="calculate-cutoff" class="section level3">
<h3>Calculate Cutoff</h3>
<p>From this dataframe, we can calculate the standard error of the
items, which is used to determine if the item has reached the stopping
rule (i.e., if the standard error reaches a defined value, it is
considered accurately measured, and we can stop sampling it). To get the
defined value, we use the 40% decile of the standard errors of the
items.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>cutoff <span class="ot">&lt;-</span> <span class="fu">calculate_cutoff</span>(<span class="at">population =</span> df, <span class="co"># pilot data or simulated data</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>  <span class="at">grouping_items =</span> <span class="st">&quot;item&quot;</span>, <span class="co"># name of the item indicator column</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>  <span class="at">score =</span> <span class="st">&quot;score&quot;</span>, <span class="co"># name of the dependent variable column</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>  <span class="at">minimum =</span> <span class="fu">min</span>(df<span class="sc">$</span>score), <span class="co"># minimum possible/found score</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>  <span class="at">maximum =</span> <span class="fu">max</span>(df<span class="sc">$</span>score)) <span class="co"># maximum possible/found score</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>                           </span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>cutoff<span class="sc">$</span>se_items <span class="co"># all standard errors of items</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="co">#&gt;  [1] 0.3920147 1.0708714 1.1341028 1.2229538 1.0577257</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="co">#&gt;  [6] 1.0177127 0.8686909 0.9484874 0.4339395 0.9412878</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co">#&gt; [11] 1.3666437 1.0084056 0.8099465 0.7877877 1.0833332</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="co">#&gt; [16] 1.4624172 1.2440920 1.2148211 1.6182107 1.3737822</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="co">#&gt; [21] 0.7382102 0.8146362 0.7408250 0.5671575 1.2728319</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="co">#&gt; [26] 1.2118386 0.6816918 0.6105171 0.5920832 1.0920425</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="co">#&gt; [31] 1.4495927 1.0026142 0.5444239 0.9605256 0.5372017</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="co">#&gt; [36] 0.9130861 0.6175753 0.8841982 1.3333519 0.5847828</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a><span class="co">#&gt; [41] 0.7523152 1.3867805 1.0585425 0.5410292 1.0476215</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="co">#&gt; [46] 0.4265040 0.7721489 1.4449187 0.9088416 1.4981560</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="co">#&gt; [51] 0.6674206 1.0049786 1.0465209 1.0159452 0.6905518</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="co">#&gt; [56] 1.3574879 0.9471974 0.5624475 1.3495594 0.9263670</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a><span class="co">#&gt; [61] 1.1375711 1.0324721 1.1059288 1.0277050 0.8997262</span></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="co">#&gt; [66] 1.3560916 1.0809033 1.2846047 1.5011117 1.0401674</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a><span class="co">#&gt; [71] 1.3945916 0.8620661 0.7431917 1.5115933 0.8433558</span></span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>cutoff<span class="sc">$</span>sd_items <span class="co"># standard deviation of the standard errors</span></span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a><span class="co">#&gt; [1] 0.3028549</span></span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a>cutoff<span class="sc">$</span>cutoff <span class="co"># 40% decile score</span></span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a><span class="co">#&gt;       40% </span></span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a><span class="co">#&gt; 0.9210546</span></span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a>cutoff<span class="sc">$</span>prop_var <span class="co"># proportion of possible variance </span></span>
<span id="cb3-29"><a href="#cb3-29" tabindex="-1"></a><span class="co">#&gt; [1] 0.006429904</span></span></code></pre></div>
</div>
<div id="simulate-samples" class="section level3">
<h3>Simulate Samples</h3>
<p>Next, we use simulation to pretend we have samples of a starting size
(we suggest 20) up to a maximum size we are willing to collect. These
samples will be used to determine the number of items that achieve our
stopping rule to determine how many participants are needed to
accurately measure most items.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">simulate_samples</span>(<span class="at">start =</span> <span class="dv">20</span>, <span class="co"># starting sample size</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>  <span class="at">stop =</span> <span class="dv">400</span>, <span class="co"># stopping sample size</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>  <span class="at">increase =</span> <span class="dv">5</span>, <span class="co"># increase bootstrapped samples by this amount</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>  <span class="at">population =</span> df, <span class="co"># population or pilot data</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>  <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="co"># bootstrap with replacement? </span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>  <span class="at">nsim =</span> <span class="dv">500</span>, <span class="co"># number of simulations to run</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>  <span class="at">grouping_items =</span> <span class="st">&quot;item&quot;</span>) <span class="co"># item column label </span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="fu">save</span>(samples, <span class="at">file =</span> <span class="st">&quot;data/simulatePriming.RData&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># since that&#39;s a slow function, we wrote out the data and read it back in</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="fu">load</span>(<span class="fu">paste0</span>(filelocation,<span class="st">&quot;/vignettes/data/simulatePriming.Rdata&quot;</span>))</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="fu">head</span>(samples[[<span class="dv">1</span>]])</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 × 2</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="co">#&gt; # Groups:   item [1]</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co">#&gt;    item score</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co">#&gt;   &lt;int&gt; &lt;dbl&gt;</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="co">#&gt; 1     1 15.8 </span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co">#&gt; 2     1 19.6 </span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a><span class="co">#&gt; 3     1 17.7 </span></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a><span class="co">#&gt; 4     1 25.6 </span></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="co">#&gt; 5     1 31.0 </span></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a><span class="co">#&gt; 6     1  5.53</span></span></code></pre></div>
</div>
<div id="calculate-proportions-of-items-measured" class="section level3">
<h3>Calculate Proportions of Items Measured</h3>
<p>From those samples and our estimated cutoff score, we can calculate
the number of items below our suggested stopping rule.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>proportion_summary <span class="ot">&lt;-</span> <span class="fu">calculate_proportion</span>(<span class="at">samples =</span> samples, <span class="co"># samples list</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>  <span class="at">cutoff =</span> cutoff<span class="sc">$</span>cutoff, <span class="co"># cut off score </span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>  <span class="at">grouping_items =</span> <span class="st">&quot;item&quot;</span>, <span class="co"># item column name</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>  <span class="at">score =</span> <span class="st">&quot;score&quot;</span>) <span class="co"># dependent variable column name </span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="fu">head</span>(proportion_summary)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 × 2</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co">#&gt;   sample_size percent_below</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="co">#&gt;         &lt;dbl&gt;         &lt;dbl&gt;</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a><span class="co">#&gt; 1          20        0.04  </span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a><span class="co">#&gt; 2          25        0.0667</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a><span class="co">#&gt; 3          30        0.08  </span></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a><span class="co">#&gt; 4          35        0.08  </span></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a><span class="co">#&gt; 5          40        0.107 </span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a><span class="co">#&gt; 6          45        0.12</span></span></code></pre></div>
</div>
<div id="final-sample-size" class="section level3">
<h3>Final Sample Size</h3>
<p>As you will note in our paper, we determined that this simulation
procedure needs a correction to approximate traditional interpretations
of power. You can use “power” levels like 80 percent, 90 percent, etc.
similarly to traditional power - use higher numbers if you want to be
more stringent to make sure all items are “well measured” (and
correspondingly you will get higher estimated sample sizes). We
suggested using 80% as a “minimum” sample size, the cutoff stopping rule
while running the study if you use adaptive sampling (or just overall to
review the data), and a higher value like 90% for a maximum sample size
to collect.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>corrected_summary <span class="ot">&lt;-</span> <span class="fu">calculate_correction</span>(</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>  <span class="at">proportion_summary =</span> proportion_summary, <span class="co"># prop from above</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>  <span class="at">pilot_sample_size =</span> <span class="dv">100</span>, <span class="co"># number of participants in the pilot data </span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>  <span class="at">proportion_variability =</span> cutoff<span class="sc">$</span>prop_var, <span class="co"># proportion variance from cutoff scores</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>  <span class="at">power_levels =</span> <span class="fu">c</span>(<span class="dv">80</span>, <span class="dv">85</span>, <span class="dv">90</span>, <span class="dv">95</span>)) <span class="co"># what levels of power to calculate </span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>corrected_summary</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 × 3</span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="co">#&gt;   percent_below sample_size corrected_sample_size</span></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="co">#&gt;           &lt;dbl&gt;       &lt;dbl&gt;                 &lt;dbl&gt;</span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="co">#&gt; 1          80           190                  104.</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="co">#&gt; 2          85.3         225                  123.</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a><span class="co">#&gt; 3          92           265                  145.</span></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a><span class="co">#&gt; 4          96           280                  153.</span></span></code></pre></div>
</div>
</div>
<div id="create-stimuli-functions" class="section level2">
<h2>Create Stimuli Functions</h2>
<p>Once you’ve determine your sample sizes, you will want to create
stimuli. These functions show you how we created stimuli from the
<code>OpenSubtitles</code> project using the <code>subs2vec</code>
project.</p>
<ul>
<li><code>OpenSubtitles</code>: <a href="https://opus.nlpl.eu/OpenSubtitles/corpus/version/OpenSubtitles" class="uri">https://opus.nlpl.eu/OpenSubtitles/corpus/version/OpenSubtitles</a></li>
<li><code>subs2vec</code>: <a href="https://github.com/jvparidon/subs2vec" class="uri">https://github.com/jvparidon/subs2vec</a>.</li>
</ul>
<div id="get-models" class="section level3">
<h3>Get Models</h3>
<p>You can review the available models from <code>subs2vec</code> merged
with the available data in <code>OpenSubtitles</code> by using the data
function. You can use <code>?subsData</code> to view the information
about the columns and the dataset.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;subsData&quot;</span>)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">tibble</span>(subsData))</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 × 10</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co">#&gt;   language_code subs_vec  subs_count wiki_vec wiki_count files</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt;</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co">#&gt; 1 hi            https://… https://h… https:/… https://h…   102</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="co">#&gt; 2 gl            https://… https://h… https:/… https://h…   449</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co">#&gt; 3 ca            https://… https://h… https:/… https://h…   832</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a><span class="co">#&gt; 4 bn            https://… https://h… https:/… https://h…   542</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="co">#&gt; 5 br            https://… https://h… https:/… https://h…    32</span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="co">#&gt; 6 bs            https://… https://h… https:/… https://h… 37309</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a><span class="co">#&gt; # ℹ 4 more variables: tokens &lt;chr&gt;, sentences &lt;chr&gt;,</span></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a><span class="co">#&gt; #   language &lt;chr&gt;, udpipe_model &lt;chr&gt;</span></span></code></pre></div>
<p>We only worked with languages in which we could use a part of speech
tagger. We recommend <code>udpipe</code> as a great package that has
many taggers. The language model necessary is shown in the
<code>udpipe_model</code> column.</p>
<p>In this example, let’s use Afrikaans as a smaller dataset for an
example. The datasets can be very large - just a warning for downloading
and using on your computer. Use the <code>import_subs</code> function to
download and import the files you are interested in.</p>
<p>For language, please use the two letter language code in the
<code>language_code</code> column of the subsData.</p>
<p>You then need to pick <code>what</code> to download:</p>
<ul>
<li><code>subs_vec</code>: The subtitles embeddings from a fastText
model.</li>
<li><code>subs_count</code>: The frequency of tokens found in the
<code>subs_vec</code> model.</li>
<li><code>wiki_vec</code>: The Wikipedia embeddings from a fastText
model.</li>
<li><code>subs_count</code>: The frequency of tokens found in the
<code>wiki_vec</code> model.</li>
</ul>
<p>You may see some warnings based on file formatting.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>af_freq <span class="ot">&lt;-</span> <span class="fu">import_subs</span>(</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>  <span class="at">language =</span> <span class="st">&quot;af&quot;</span>,</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>  <span class="at">what =</span> <span class="st">&quot;subs_count&quot;</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="fu">head</span>(af_freq)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co">#&gt;   unigram unigram_freq</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co">#&gt; 1     die        12673</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="co">#&gt; 2     nie        11788</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="co">#&gt; 3      ek        11605</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co">#&gt; 4      is         9147</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="co">#&gt; 5     het         8109</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co">#&gt; 6      jy         7425</span></span></code></pre></div>
<p>We then used <code>udpipe</code> to filter our possible options. You
may have other criteria, but here’s an example of how we tagged concepts
(for their main part of speech, given no sentence context here). When
you use this function, it will download the model necessary for
tagging.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># tag with udpipe</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>af_tagged <span class="ot">&lt;-</span> <span class="fu">udpipe</span>(af_freq<span class="sc">$</span>unigram, </span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>                    <span class="at">object =</span> subsData<span class="sc">$</span>udpipe_model[subsData<span class="sc">$</span>language_code <span class="sc">==</span> <span class="st">&quot;af&quot;</span>], </span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>                    <span class="at">parser =</span> <span class="st">&quot;none&quot;</span>)</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">tibble</span>(af_tagged))</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 × 17</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a><span class="co">#&gt;   doc_id paragraph_id sentence_id sentence start   end term_id</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;         &lt;int&gt;       &lt;int&gt; &lt;chr&gt;    &lt;int&gt; &lt;int&gt;   &lt;int&gt;</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a><span class="co">#&gt; 1 doc1              1           1 die          1     3       1</span></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a><span class="co">#&gt; 2 doc2              1           1 nie          1     3       1</span></span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a><span class="co">#&gt; 3 doc3              1           1 ek           1     2       1</span></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a><span class="co">#&gt; 4 doc4              1           1 is           1     2       1</span></span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a><span class="co">#&gt; 5 doc5              1           1 het          1     3       1</span></span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a><span class="co">#&gt; 6 doc6              1           1 jy           1     2       1</span></span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a><span class="co">#&gt; # ℹ 10 more variables: token_id &lt;chr&gt;, token &lt;chr&gt;,</span></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a><span class="co">#&gt; #   lemma &lt;chr&gt;, upos &lt;chr&gt;, xpos &lt;chr&gt;, feats &lt;chr&gt;,</span></span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a><span class="co">#&gt; #   head_token_id &lt;chr&gt;, dep_rel &lt;chr&gt;, deps &lt;chr&gt;,</span></span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a><span class="co">#&gt; #   misc &lt;chr&gt;</span></span></code></pre></div>
<p>We then:</p>
<ul>
<li>Lower cased</li>
<li>Removed anything less than three characters when appropriate</li>
<li>Picked words only in nouns, verbs, adjectives, and adverbs</li>
<li>Took out stopwords</li>
<li>Took out words with numbers</li>
</ul>
<p>We only used the top 10,000 words for the next section, but this
selection will depend on your use case as well.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># word_choice</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>word_choice <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;NOUN&quot;</span>, <span class="st">&quot;VERB&quot;</span>, <span class="st">&quot;ADJ&quot;</span>, <span class="st">&quot;ADV&quot;</span>)</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="co"># lower case</span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>af_tagged<span class="sc">$</span>lemma <span class="ot">&lt;-</span> <span class="fu">tolower</span>(af_tagged<span class="sc">$</span>lemma)</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a><span class="co"># three characters </span></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>af_tagged <span class="ot">&lt;-</span> <span class="fu">subset</span>(af_tagged, <span class="fu">nchar</span>(af_tagged<span class="sc">$</span>lemma) <span class="sc">&gt;=</span> <span class="dv">3</span>)</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a><span class="co"># only nouns verbs, etc. </span></span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>af_tagged <span class="ot">&lt;-</span> <span class="fu">subset</span>(af_tagged, upos <span class="sc">%in%</span> word_choice)</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a><span class="co"># removed stop words just in case they were incorrectly tagged</span></span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a>af_tagged <span class="ot">&lt;-</span> <span class="fu">subset</span>(af_tagged, <span class="sc">!</span>(lemma <span class="sc">%in%</span> <span class="fu">stopwords</span>(<span class="at">language =</span> <span class="st">&quot;af&quot;</span>, <span class="at">source =</span> <span class="st">&quot;stopwords-iso&quot;</span>)))</span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a><span class="co"># removed things with numbers</span></span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>af_tagged <span class="ot">&lt;-</span> <span class="fu">subset</span>(af_tagged, <span class="sc">!</span>(<span class="fu">grepl</span>(<span class="st">&quot;[0-9]&quot;</span>, af_tagged<span class="sc">$</span>sentence)))</span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a><span class="co"># merge frequency back into tagged list</span></span>
<span id="cb12-20"><a href="#cb12-20" tabindex="-1"></a><span class="co"># merge by sentence so one to one match</span></span>
<span id="cb12-21"><a href="#cb12-21" tabindex="-1"></a><span class="fu">colnames</span>(af_freq) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;sentence&quot;</span>, <span class="st">&quot;freq&quot;</span>)</span>
<span id="cb12-22"><a href="#cb12-22" tabindex="-1"></a>af_final <span class="ot">&lt;-</span> <span class="fu">merge</span>(af_tagged, af_freq, <span class="at">by =</span> <span class="st">&quot;sentence&quot;</span>, <span class="at">all.x =</span> T)</span>
<span id="cb12-23"><a href="#cb12-23" tabindex="-1"></a></span>
<span id="cb12-24"><a href="#cb12-24" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">tibble</span>(af_final))</span>
<span id="cb12-25"><a href="#cb12-25" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 × 18</span></span>
<span id="cb12-26"><a href="#cb12-26" tabindex="-1"></a><span class="co">#&gt;   sentence doc_id paragraph_id sentence_id start   end term_id</span></span>
<span id="cb12-27"><a href="#cb12-27" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;chr&gt;         &lt;int&gt;       &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;</span></span>
<span id="cb12-28"><a href="#cb12-28" tabindex="-1"></a><span class="co">#&gt; 1 aanbeve… doc17…            1           1     1    11       1</span></span>
<span id="cb12-29"><a href="#cb12-29" tabindex="-1"></a><span class="co">#&gt; 2 aanbewe… doc81…            1           1     1     9       1</span></span>
<span id="cb12-30"><a href="#cb12-30" tabindex="-1"></a><span class="co">#&gt; 3 aanbied  doc13…            1           1     1     7       1</span></span>
<span id="cb12-31"><a href="#cb12-31" tabindex="-1"></a><span class="co">#&gt; 4 aanbreek doc82…            1           1     1     8       1</span></span>
<span id="cb12-32"><a href="#cb12-32" tabindex="-1"></a><span class="co">#&gt; 5 aanbring doc14…            1           1     1     8       1</span></span>
<span id="cb12-33"><a href="#cb12-33" tabindex="-1"></a><span class="co">#&gt; 6 aandadig doc57…            1           1     1     8       1</span></span>
<span id="cb12-34"><a href="#cb12-34" tabindex="-1"></a><span class="co">#&gt; # ℹ 11 more variables: token_id &lt;chr&gt;, token &lt;chr&gt;,</span></span>
<span id="cb12-35"><a href="#cb12-35" tabindex="-1"></a><span class="co">#&gt; #   lemma &lt;chr&gt;, upos &lt;chr&gt;, xpos &lt;chr&gt;, feats &lt;chr&gt;,</span></span>
<span id="cb12-36"><a href="#cb12-36" tabindex="-1"></a><span class="co">#&gt; #   head_token_id &lt;chr&gt;, dep_rel &lt;chr&gt;, deps &lt;chr&gt;,</span></span>
<span id="cb12-37"><a href="#cb12-37" tabindex="-1"></a><span class="co">#&gt; #   misc &lt;chr&gt;, freq &lt;int&gt;</span></span>
<span id="cb12-38"><a href="#cb12-38" tabindex="-1"></a></span>
<span id="cb12-39"><a href="#cb12-39" tabindex="-1"></a><span class="co"># eliminate duplicates by lemma</span></span>
<span id="cb12-40"><a href="#cb12-40" tabindex="-1"></a>af_final <span class="ot">&lt;-</span> af_final[<span class="fu">order</span>(af_final<span class="sc">$</span>freq, <span class="at">decreasing =</span> <span class="cn">TRUE</span>) , ]</span>
<span id="cb12-41"><a href="#cb12-41" tabindex="-1"></a>af_final <span class="ot">&lt;-</span> af_final[<span class="sc">!</span><span class="fu">duplicated</span>(af_final<span class="sc">$</span>lemma), ]</span>
<span id="cb12-42"><a href="#cb12-42" tabindex="-1"></a></span>
<span id="cb12-43"><a href="#cb12-43" tabindex="-1"></a><span class="co"># grab top 10K</span></span>
<span id="cb12-44"><a href="#cb12-44" tabindex="-1"></a>af_top <span class="ot">&lt;-</span> af_final[<span class="dv">1</span><span class="sc">:</span><span class="dv">10000</span> , ]</span></code></pre></div>
<p>Next, we used <code>import_subs()</code> again import the embeddings
for the subtitles.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>af_dims <span class="ot">&lt;-</span> <span class="fu">import_subs</span>(</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>  <span class="at">language =</span> <span class="st">&quot;af&quot;</span>,</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>  <span class="at">what =</span> <span class="st">&quot;subs_vec&quot;</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">tibble</span>(af_dims))</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 × 301</span></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a><span class="co">#&gt;   V1           V2        V3      V4      V5     V6        V7</span></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a><span class="co">#&gt; 1 &lt;/s&gt;  -0.236     0.0544    0.0202 -0.0531  0.146  0.000971</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="co">#&gt; 2 nie   -0.000683  0.0787    0.0382  0.0379  0.295  0.225   </span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a><span class="co">#&gt; 3 die   -0.0233   -0.000478  0.191  -0.103   0.176 -0.0884  </span></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="co">#&gt; 4 is    -0.410     0.144     0.133  -0.104   0.295 -0.0391  </span></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a><span class="co">#&gt; 5 het    0.344    -0.0163   -0.198   0.259  -0.579 -0.154   </span></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a><span class="co">#&gt; 6 n      0.0615   -0.139    -0.0674 -0.0658 -0.105 -0.212   </span></span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a><span class="co">#&gt; # ℹ 294 more variables: V8 &lt;dbl&gt;, V9 &lt;dbl&gt;, V10 &lt;dbl&gt;,</span></span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a><span class="co">#&gt; #   V11 &lt;dbl&gt;, V12 &lt;dbl&gt;, V13 &lt;dbl&gt;, V14 &lt;dbl&gt;, V15 &lt;dbl&gt;,</span></span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a><span class="co">#&gt; #   V16 &lt;dbl&gt;, V17 &lt;dbl&gt;, V18 &lt;dbl&gt;, V19 &lt;dbl&gt;, V20 &lt;dbl&gt;,</span></span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a><span class="co">#&gt; #   V21 &lt;dbl&gt;, V22 &lt;dbl&gt;, V23 &lt;dbl&gt;, V24 &lt;dbl&gt;, V25 &lt;dbl&gt;,</span></span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a><span class="co">#&gt; #   V26 &lt;dbl&gt;, V27 &lt;dbl&gt;, V28 &lt;dbl&gt;, V29 &lt;dbl&gt;, V30 &lt;dbl&gt;,</span></span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a><span class="co">#&gt; #   V31 &lt;dbl&gt;, V32 &lt;dbl&gt;, V33 &lt;dbl&gt;, V34 &lt;dbl&gt;, V35 &lt;dbl&gt;,</span></span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a><span class="co">#&gt; #   V36 &lt;dbl&gt;, V37 &lt;dbl&gt;, V38 &lt;dbl&gt;, V39 &lt;dbl&gt;, V40 &lt;dbl&gt;, …</span></span></code></pre></div>
<p>In our case, we want to use the tokens as row names, so we want to
move the first column to the row names and delete it to have a 300
dimension by tokens matrix.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co"># lower case</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>af_dims<span class="sc">$</span>V1 <span class="ot">&lt;-</span> <span class="fu">tolower</span>(af_dims[ , <span class="dv">1</span>]) <span class="co"># first column is always the tokens</span></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a><span class="co"># eliminate duplicates </span></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>af_dims <span class="ot">&lt;-</span> <span class="fu">subset</span>(af_dims, <span class="sc">!</span><span class="fu">duplicated</span>(af_dims[ , <span class="dv">1</span>]))</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a><span class="co"># make row names</span></span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a><span class="fu">rownames</span>(af_dims) <span class="ot">&lt;-</span> af_dims[ , <span class="dv">1</span>]</span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>af_dims <span class="ot">&lt;-</span> af_dims[ , <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">tibble</span>(af_dims))</span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 × 300</span></span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a><span class="co">#&gt;          V2        V3      V4      V5     V6       V7       V8</span></span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a><span class="co">#&gt;       &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a><span class="co">#&gt; 1 -0.236     0.0544    0.0202 -0.0531  0.146  9.71e-4  0.0146 </span></span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a><span class="co">#&gt; 2 -0.000683  0.0787    0.0382  0.0379  0.295  2.25e-1 -0.171  </span></span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a><span class="co">#&gt; 3 -0.0233   -0.000478  0.191  -0.103   0.176 -8.84e-2 -0.0828 </span></span>
<span id="cb15-17"><a href="#cb15-17" tabindex="-1"></a><span class="co">#&gt; 4 -0.410     0.144     0.133  -0.104   0.295 -3.91e-2 -0.00618</span></span>
<span id="cb15-18"><a href="#cb15-18" tabindex="-1"></a><span class="co">#&gt; 5  0.344    -0.0163   -0.198   0.259  -0.579 -1.54e-1  0.131  </span></span>
<span id="cb15-19"><a href="#cb15-19" tabindex="-1"></a><span class="co">#&gt; 6  0.0615   -0.139    -0.0674 -0.0658 -0.105 -2.12e-1 -0.115  </span></span>
<span id="cb15-20"><a href="#cb15-20" tabindex="-1"></a><span class="co">#&gt; # ℹ 293 more variables: V9 &lt;dbl&gt;, V10 &lt;dbl&gt;, V11 &lt;dbl&gt;,</span></span>
<span id="cb15-21"><a href="#cb15-21" tabindex="-1"></a><span class="co">#&gt; #   V12 &lt;dbl&gt;, V13 &lt;dbl&gt;, V14 &lt;dbl&gt;, V15 &lt;dbl&gt;, V16 &lt;dbl&gt;,</span></span>
<span id="cb15-22"><a href="#cb15-22" tabindex="-1"></a><span class="co">#&gt; #   V17 &lt;dbl&gt;, V18 &lt;dbl&gt;, V19 &lt;dbl&gt;, V20 &lt;dbl&gt;, V21 &lt;dbl&gt;,</span></span>
<span id="cb15-23"><a href="#cb15-23" tabindex="-1"></a><span class="co">#&gt; #   V22 &lt;dbl&gt;, V23 &lt;dbl&gt;, V24 &lt;dbl&gt;, V25 &lt;dbl&gt;, V26 &lt;dbl&gt;,</span></span>
<span id="cb15-24"><a href="#cb15-24" tabindex="-1"></a><span class="co">#&gt; #   V27 &lt;dbl&gt;, V28 &lt;dbl&gt;, V29 &lt;dbl&gt;, V30 &lt;dbl&gt;, V31 &lt;dbl&gt;,</span></span>
<span id="cb15-25"><a href="#cb15-25" tabindex="-1"></a><span class="co">#&gt; #   V32 &lt;dbl&gt;, V33 &lt;dbl&gt;, V34 &lt;dbl&gt;, V35 &lt;dbl&gt;, V36 &lt;dbl&gt;,</span></span>
<span id="cb15-26"><a href="#cb15-26" tabindex="-1"></a><span class="co">#&gt; #   V37 &lt;dbl&gt;, V38 &lt;dbl&gt;, V39 &lt;dbl&gt;, V40 &lt;dbl&gt;, V41 &lt;dbl&gt;, …</span></span></code></pre></div>
</div>
<div id="calculate-similarity" class="section level3">
<h3>Calculate Similarity</h3>
<p>We can then use the <code>calculate_similarity()</code> function to
get the similarity values for all words based on the dimension matrix.
The underlying function is cosine calculated between vectors of the two
word dimensions.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>af_cosine <span class="ot">&lt;-</span> </span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>  <span class="fu">calculate_similarity</span>(</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>    <span class="at">words =</span> af_final<span class="sc">$</span>sentence, <span class="co"># the tokens you want to filter</span></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>    <span class="at">dimensions =</span> af_dims, <span class="co"># the matrix of items </span></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>    <span class="at">by =</span> <span class="dv">1</span> <span class="co"># 1 for rows, 2 for columns </span></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>)</span></code></pre></div>
<p>The <code>top_n</code> function can be used to calculate the top
number of cosine values for each token in the similarity matrix. Please
note: it will always return the token-token combination as 1 (the token
related to itself), so you should ask for n+1 number of cosines to then
filter out the token-token combinations. Big thanks to Brenton Wiernik
who figured out how to make this computational efficient.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="co"># get the top 5 related words </span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>af_top_sim <span class="ot">&lt;-</span> semanticprimeR<span class="sc">::</span><span class="fu">top_n</span>(af_cosine, <span class="dv">6</span>)</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>af_top_sim <span class="ot">&lt;-</span> <span class="fu">subset</span>(af_top_sim, cue<span class="sc">!=</span>target)</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a><span class="fu">head</span>(af_top_sim)</span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a><span class="co">#&gt;    cue  target    cosine</span></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a><span class="co">#&gt; 2  nou     als 0.8654161</span></span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a><span class="co">#&gt; 3  nou   nitto 0.8476698</span></span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a><span class="co">#&gt; 4  nou    juis 0.8434761</span></span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a><span class="co">#&gt; 5  nou nicolas 0.8419336</span></span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a><span class="co">#&gt; 6  nou jakkals 0.8278382</span></span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a><span class="co">#&gt; 8 hier    bier 0.8086171</span></span></code></pre></div>
</div>
<div id="create-pseudowords" class="section level3">
<h3>Create Pseudowords</h3>
<p>We originally set up a function to create words by replacing the
number of characters based on the bigrams in the token. We recommend you
use the other function based on Wuggy, but you can also do simple
replacement.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>af_top_sim<span class="sc">$</span>fake_cue <span class="ot">&lt;-</span> <span class="fu">fake_simple</span>(af_top_sim<span class="sc">$</span>cue)</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="co"># you&#39;d want to also do this based on target depending on your study </span></span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a><span class="fu">head</span>(af_top_sim)</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a><span class="co">#&gt;    cue  target    cosine fake_cue</span></span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a><span class="co">#&gt; 2  nou     als 0.8654161      nuu</span></span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a><span class="co">#&gt; 3  nou   nitto 0.8476698      dou</span></span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a><span class="co">#&gt; 4  nou    juis 0.8434761      non</span></span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a><span class="co">#&gt; 5  nou nicolas 0.8419336      nob</span></span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a><span class="co">#&gt; 6  nou jakkals 0.8278382      wou</span></span>
<span id="cb18-10"><a href="#cb18-10" tabindex="-1"></a><span class="co">#&gt; 8 hier    bier 0.8086171     gier</span></span></code></pre></div>
<p>You can also use the Wuggy algorithm using <code>fake_Wuggy()</code>.
<em>This function is not fast. It is slower the larger the size of the
words to create from.</em> It returns a dataframe of options to use for
pseudowords with the following columns:</p>
<ul>
<li><code>word_id</code>: Number id for each unique word.</li>
<li><code>first</code>: First syllable in pairs of syllables.</li>
<li><code>original_pair</code>: Pair of syllables together.</li>
<li><code>second</code>: Second syllable in the pairs of syllables.</li>
<li><code>syll</code>: Number of syllables in the token.</li>
<li><code>original_freq</code>: Frequency of the syllable pair.</li>
<li><code>replacement_pair</code>: Replacement option wherein one of the
syllables has been changed.</li>
<li><code>replacement_syll</code>: The replacement syllable.</li>
<li><code>replacement_freq</code>: The frequency of the replacement
syllable pair.</li>
<li><code>freq_diff</code>: The difference in frequency of the
transition pair.</li>
<li><code>char_diff</code>: Number of characters difference in the
original pair and the replacement pair.</li>
<li><code>letter_diff</code>: Number of letters difference in the
original pair and the replacement pair. If the replacement includes the
same letters, the difference would be zero. These values are excluded
from being options.}</li>
<li><code>original_word</code>: The original token.}</li>
<li><code>replacement_word</code>: The final replacement token.</li>
</ul>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>af_wuggy <span class="ot">&lt;-</span> <span class="fu">fake_Wuggy</span>(</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>  <span class="at">wordlist =</span> af_final<span class="sc">$</span>sentence, <span class="co"># full valid options in language</span></span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>  <span class="at">language_hyp =</span> <span class="fu">paste0</span>(filelocation,<span class="st">&quot;/inst/latex/hyph-af.tex&quot;</span>), <span class="co"># path to hyphenation.tex </span></span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>  <span class="at">lang =</span> <span class="st">&quot;af&quot;</span>, <span class="co"># two letter language code</span></span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>  replacewords <span class="ot">&lt;-</span> <span class="fu">unique</span>(af_top_sim<span class="sc">$</span>cue[<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>]) <span class="co"># words you want to create pseudowords for  </span></span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a>)</span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a><span class="co">#&gt;   |                                                            |                                                    |   0%  |                                                            |                                                    |   1%  |                                                            |=                                                   |   1%  |                                                            |=                                                   |   2%  |                                                            |=                                                   |   3%  |                                                            |==                                                  |   3%  |                                                            |==                                                  |   4%  |                                                            |==                                                  |   5%  |                                                            |===                                                 |   5%  |                                                            |===                                                 |   6%  |                                                            |===                                                 |   7%  |                                                            |====                                                |   7%  |                                                            |====                                                |   8%  |                                                            |====                                                |   9%  |                                                            |=====                                               |   9%  |                                                            |=====                                               |  10%  |                                                            |=====                                               |  11%  |                                                            |======                                              |  11%  |                                                            |======                                              |  12%  |                                                            |=======                                             |  13%  |                                                            |=======                                             |  14%  |                                                            |========                                            |  14%  |                                                            |========                                            |  15%  |                                                            |========                                            |  16%  |                                                            |=========                                           |  16%  |                                                            |=========                                           |  17%  |                                                            |=========                                           |  18%  |                                                            |==========                                          |  18%  |                                                            |==========                                          |  19%  |                                                            |==========                                          |  20%  |                                                            |===========                                         |  20%  |                                                            |===========                                         |  21%  |                                                            |===========                                         |  22%  |                                                            |============                                        |  22%  |                                                            |============                                        |  23%  |                                                            |============                                        |  24%  |                                                            |=============                                       |  24%  |                                                            |=============                                       |  25%  |                                                            |=============                                       |  26%  |                                                            |==============                                      |  26%  |                                                            |==============                                      |  27%  |                                                            |==============                                      |  28%  |                                                            |===============                                     |  28%  |                                                            |===============                                     |  29%  |                                                            |===============                                     |  30%  |                                                            |================                                    |  30%  |                                                            |================                                    |  31%  |                                                            |================                                    |  32%  |                                                            |=================                                   |  32%  |                                                            |=================                                   |  33%  |                                                            |=================                                   |  34%  |                                                            |==================                                  |  34%  |                                                            |==================                                  |  35%  |                                                            |==================                                  |  36%  |                                                            |===================                                 |  36%  |                                                            |===================                                 |  37%  |                                                            |====================                                |  38%  |                                                            |====================                                |  39%  |                                                            |=====================                               |  39%  |                                                            |=====================                               |  40%  |                                                            |=====================                               |  41%  |                                                            |======================                              |  41%  |                                                            |======================                              |  42%  |                                                            |======================                              |  43%  |                                                            |=======================                             |  43%  |                                                            |=======================                             |  44%  |                                                            |=======================                             |  45%  |                                                            |========================                            |  45%  |                                                            |========================                            |  46%  |                                                            |========================                            |  47%  |                                                            |=========================                           |  47%  |                                                            |=========================                           |  48%  |                                                            |=========================                           |  49%  |                                                            |==========================                          |  49%  |                                                            |==========================                          |  50%  |                                                            |==========================                          |  51%  |                                                            |===========================                         |  51%  |                                                            |===========================                         |  52%  |                                                            |===========================                         |  53%  |                                                            |============================                        |  53%  |                                                            |============================                        |  54%  |                                                            |============================                        |  55%  |                                                            |=============================                       |  55%  |                                                            |=============================                       |  56%  |                                                            |=============================                       |  57%  |                                                            |==============================                      |  57%  |                                                            |==============================                      |  58%  |                                                            |==============================                      |  59%  |                                                            |===============================                     |  59%  |                                                            |===============================                     |  60%  |                                                            |===============================                     |  61%  |                                                            |================================                    |  61%  |                                                            |================================                    |  62%  |                                                            |=================================                   |  63%  |                                                            |=================================                   |  64%  |                                                            |==================================                  |  64%  |                                                            |==================================                  |  65%  |                                                            |==================================                  |  66%  |                                                            |===================================                 |  66%  |                                                            |===================================                 |  67%  |                                                            |===================================                 |  68%  |                                                            |====================================                |  68%  |                                                            |====================================                |  69%  |                                                            |====================================                |  70%  |                                                            |=====================================               |  70%  |                                                            |=====================================               |  71%  |                                                            |=====================================               |  72%  |                                                            |======================================              |  72%  |                                                            |======================================              |  73%  |                                                            |======================================              |  74%  |                                                            |=======================================             |  74%  |                                                            |=======================================             |  75%  |                                                            |=======================================             |  76%  |                                                            |========================================            |  76%  |                                                            |========================================            |  77%  |                                                            |========================================            |  78%  |                                                            |=========================================           |  78%  |                                                            |=========================================           |  79%  |                                                            |=========================================           |  80%  |                                                            |==========================================          |  80%  |                                                            |==========================================          |  81%  |                                                            |==========================================          |  82%  |                                                            |===========================================         |  82%  |                                                            |===========================================         |  83%  |                                                            |===========================================         |  84%  |                                                            |============================================        |  84%  |                                                            |============================================        |  85%  |                                                            |============================================        |  86%  |                                                            |=============================================       |  86%  |                                                            |=============================================       |  87%  |                                                            |==============================================      |  88%  |                                                            |==============================================      |  89%  |                                                            |===============================================     |  89%  |                                                            |===============================================     |  90%  |                                                            |===============================================     |  91%  |                                                            |================================================    |  91%  |                                                            |================================================    |  92%  |                                                            |================================================    |  93%  |                                                            |=================================================   |  93%  |                                                            |=================================================   |  94%  |                                                            |=================================================   |  95%  |                                                            |==================================================  |  95%  |                                                            |==================================================  |  96%  |                                                            |==================================================  |  97%  |                                                            |=================================================== |  97%  |                                                            |=================================================== |  98%  |                                                            |=================================================== |  99%  |                                                            |====================================================|  99%  |                                                            |====================================================| 100%</span></span>
<span id="cb19-8"><a href="#cb19-8" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">tibble</span>(af_wuggy))</span>
<span id="cb19-10"><a href="#cb19-10" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 × 14</span></span>
<span id="cb19-11"><a href="#cb19-11" tabindex="-1"></a><span class="co">#&gt;   word_id first       original_pair second  syll original_freq</span></span>
<span id="cb19-12"><a href="#cb19-12" tabindex="-1"></a><span class="co">#&gt;     &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;         &lt;chr&gt;  &lt;dbl&gt;         &lt;dbl&gt;</span></span>
<span id="cb19-13"><a href="#cb19-13" tabindex="-1"></a><span class="co">#&gt; 1       2 first_blank first_blank-… hi         1             5</span></span>
<span id="cb19-14"><a href="#cb19-14" tabindex="-1"></a><span class="co">#&gt; 2       3 ne          ne-t          t          1             1</span></span>
<span id="cb19-15"><a href="#cb19-15" tabindex="-1"></a><span class="co">#&gt; 3       1 first_blank first_blank-… no         1            22</span></span>
<span id="cb19-16"><a href="#cb19-16" tabindex="-1"></a><span class="co">#&gt; 4       4 first_blank first_blank-… we         1            23</span></span>
<span id="cb19-17"><a href="#cb19-17" tabindex="-1"></a><span class="co">#&gt; # ℹ 8 more variables: replacement_pair &lt;chr&gt;,</span></span>
<span id="cb19-18"><a href="#cb19-18" tabindex="-1"></a><span class="co">#&gt; #   replacement_syll &lt;chr&gt;, replacement_freq &lt;int&gt;,</span></span>
<span id="cb19-19"><a href="#cb19-19" tabindex="-1"></a><span class="co">#&gt; #   freq_diff &lt;dbl&gt;, char_diff &lt;int&gt;, letter_diff &lt;dbl&gt;,</span></span>
<span id="cb19-20"><a href="#cb19-20" tabindex="-1"></a><span class="co">#&gt; #   original_word &lt;chr&gt;, replacement_word &lt;chr&gt;</span></span>
<span id="cb19-21"><a href="#cb19-21" tabindex="-1"></a></span>
<span id="cb19-22"><a href="#cb19-22" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" tabindex="-1"></a><span class="fu">getwd</span>()</span>
<span id="cb19-24"><a href="#cb19-24" tabindex="-1"></a><span class="co">#&gt; [1] &quot;/Users/erinbuchanan/GitHub/Research/2_projects/PSA_Projects/SPAML/semanticprimeR/vignettes&quot;</span></span></code></pre></div>
</div>
</div>
<div id="get-priming-data" class="section level2">
<h2>Get Priming Data</h2>
<p>You can load one of the many files included in the SPAML release by
using the <code>primeData</code> to see what we have available. The
datasets are broken into a couple types:</p>
<ul>
<li><code>procedure_stimuli</code>: The stimuli from the study. Each
dataset includes the ~5000 trials used in the study listed as cue-target
pairs with their <code>cue_type</code>/<code>target_type</code>
(word/nonword) and trial <code>type</code> (related, unrelated,
nonword). The cosine values from the subs2vec models are included when
available for word pairs. If the value is blank or NA, you can assume
one of the words did not exist in the subs2vec model or could not be
matched. The subs2vec models were often filtered to only the top X
words, and some stimuli selected may have be infrequent.</li>
<li><code>matched_stimuli</code>: The matched stimuli datasets fall into
two types: “matched” which matches the original language to English, and
“unique” which includes the word pair combo found in the datasets that
makes each trial unique. Some targets were repeated due to translation -
therefore, the unique datasets allow you to unambiguously match things
together. The <code>matched_stimuli.csv</code> files has these all
matched together if you want all languages at once. The missing data is
the Arabic pairs we were asked to remove due to their taboo nature in
that culture.</li>
</ul>
<p>Each of the following files have codebooks found at: <a href="https://github.com/SemanticPriming/SPAML/tree/master/05_Data/codebooks" class="uri">https://github.com/SemanticPriming/SPAML/tree/master/05_Data/codebooks</a></p>
<ul>
<li><code>participant_data</code>: Information on the participants who
completed each language.</li>
<li><code>full_data</code>: The “raw” data with only identifiers
removed.</li>
<li><code>trial_data</code>: The trial level data showing only the trial
blocks (i.e., excluding the other lines that indicate the timing and
inter-trial interval).</li>
<li><code>item_data</code>: The average results for each token/item,
ignoring the condition presented.</li>
<li><code>priming_data</code>: The priming data in either
<code>_trials</code> format (meaning these have been matched and labeled
for trial type) or <code>_summary</code> format (meaning
averages/summaries of the target trials matched by related and unrelated
to create a priming score).</li>
</ul>
<div id="load-available-data" class="section level3">
<h3>Load Available Data</h3>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;primeData&quot;</span>)</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a><span class="fu">head</span>(primeData)</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a><span class="co">#&gt;           type                            filename language</span></span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a><span class="co">#&gt; 1    item_data           ar_answered_item_data.csv       ar</span></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a><span class="co">#&gt; 2 priming_data ar_answered_prime_summary_no2.5.csv       ar</span></span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a><span class="co">#&gt; 3 priming_data ar_answered_prime_summary_no3.0.csv       ar</span></span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a><span class="co">#&gt; 4 priming_data       ar_answered_prime_summary.csv       ar</span></span>
<span id="cb20-8"><a href="#cb20-8" tabindex="-1"></a><span class="co">#&gt; 5 priming_data        ar_answered_prime_trials.csv       ar</span></span>
<span id="cb20-9"><a href="#cb20-9" tabindex="-1"></a><span class="co">#&gt; 6    full_data                 ar_full_data.csv.gz       ar</span></span>
<span id="cb20-10"><a href="#cb20-10" tabindex="-1"></a><span class="co">#&gt;                                                                                                location</span></span>
<span id="cb20-11"><a href="#cb20-11" tabindex="-1"></a><span class="co">#&gt; 1           https://github.com/SemanticPriming/SPAML/releases/download/v1.0.1/ar_answered_item_data.csv</span></span>
<span id="cb20-12"><a href="#cb20-12" tabindex="-1"></a><span class="co">#&gt; 2 https://github.com/SemanticPriming/SPAML/releases/download/v1.0.1/ar_answered_prime_summary_no2.5.csv</span></span>
<span id="cb20-13"><a href="#cb20-13" tabindex="-1"></a><span class="co">#&gt; 3 https://github.com/SemanticPriming/SPAML/releases/download/v1.0.1/ar_answered_prime_summary_no3.0.csv</span></span>
<span id="cb20-14"><a href="#cb20-14" tabindex="-1"></a><span class="co">#&gt; 4       https://github.com/SemanticPriming/SPAML/releases/download/v1.0.1/ar_answered_prime_summary.csv</span></span>
<span id="cb20-15"><a href="#cb20-15" tabindex="-1"></a><span class="co">#&gt; 5        https://github.com/SemanticPriming/SPAML/releases/download/v1.0.1/ar_answered_prime_trials.csv</span></span>
<span id="cb20-16"><a href="#cb20-16" tabindex="-1"></a><span class="co">#&gt; 6                 https://github.com/SemanticPriming/SPAML/releases/download/v1.0.1/ar_full_data.csv.gz</span></span></code></pre></div>
<p>Once you decide what file you would like to download and import, you
can use <code>import_prime()</code> to import that file. Note that some
of the <code>full_data</code> datasets are quite large and may take a
while download and/or import directly. You can also just use the direct
links the primeData file to download them. Some files are heavily
compressed in <code>.gz</code> format. I recommend 7-zip if you aren’t
familiar with the command line to unzip these: <a href="https://www.wikihow.com/Extract-a-Gz-File" class="uri">https://www.wikihow.com/Extract-a-Gz-File</a></p>
<p>You can also import them directly into <em>R</em> with the
<em>rio</em> package (which is what this function does, but it does
download the file each time, so I’d recommend one download and then put
the import into your code directly with
<code>rio::import(&quot;filepath&quot;)</code>).</p>
</div>
<div id="import-specific-data" class="section level3">
<h3>Import Specific Data</h3>
<p>In this example, we import the stimuli dataset for Spanish, which
includes the trials, type of trial information, and the cosine
calculated from subs2vec.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>es_words <span class="ot">&lt;-</span> <span class="fu">import_prime</span>(<span class="st">&quot;es_words.csv&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="fu">head</span>(es_words)</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a><span class="co">#&gt;     es_cue es_target    type cue_type target_type es_cosine</span></span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a><span class="co">#&gt; 1 lenguado   abadejo related     word        word 0.5712210</span></span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a><span class="co">#&gt; 2    dejar abandonar related     word        word 0.5418134</span></span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a><span class="co">#&gt; 3  espalda   abdomen related     word        word 0.4251472</span></span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a><span class="co">#&gt; 4     beso    abrazo related     word        word 0.7530440</span></span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a><span class="co">#&gt; 5 ridículo   absurdo related     word        word 0.7036410</span></span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a><span class="co">#&gt; 6   abuelo    abuela related     word        word 0.7450651</span></span></code></pre></div>
</div>
</div>
<div id="match-to-lab-data" class="section level2">
<h2>Match to LAB Data</h2>
<div id="load-available-data-1" class="section level3">
<h3>Load Available Data</h3>
<p>To review the available data from the Linguistic Annotated
Bibliography, you can use <code>data(&quot;labData&quot;)</code>, which includes
information about available datasets overall and which are included in
our LAB data release for merging.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;labData&quot;</span>)</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">tibble</span>(labData))</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 × 73</span></span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a><span class="co">#&gt;   included bibtex         author    year ref_title ref_journal</span></span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;      </span></span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a><span class="co">#&gt; 1 no       Adelman2014    Adelman…  2014 &quot;A behav… Behavior R…</span></span>
<span id="cb23-7"><a href="#cb23-7" tabindex="-1"></a><span class="co">#&gt; 2 no       Aguilar2017    Aguilar…  2017 &quot;Develop… 2017 IEEE …</span></span>
<span id="cb23-8"><a href="#cb23-8" tabindex="-1"></a><span class="co">#&gt; 3 no       Akinina2015    Akinina…  2014 &quot;Russian… Behavior R…</span></span>
<span id="cb23-9"><a href="#cb23-9" tabindex="-1"></a><span class="co">#&gt; 4 no       Al-Sulaiti2006 Al-Sula…  2006 &quot;The Des… Internatio…</span></span>
<span id="cb23-10"><a href="#cb23-10" tabindex="-1"></a><span class="co">#&gt; 5 no       Alameda1995    Alameda…  1995 &quot;Diccion… Servicio d…</span></span>
<span id="cb23-11"><a href="#cb23-11" tabindex="-1"></a><span class="co">#&gt; 6 yes      Alario1999     Alario …  1999 &quot;A set o… Behavior R…</span></span>
<span id="cb23-12"><a href="#cb23-12" tabindex="-1"></a><span class="co">#&gt; # ℹ 67 more variables: ref_volume &lt;chr&gt;, ref_page &lt;chr&gt;,</span></span>
<span id="cb23-13"><a href="#cb23-13" tabindex="-1"></a><span class="co">#&gt; #   ref_doi &lt;chr&gt;, no1 &lt;chr&gt;, no2 &lt;int&gt;, type1 &lt;chr&gt;,</span></span>
<span id="cb23-14"><a href="#cb23-14" tabindex="-1"></a><span class="co">#&gt; #   ref1 &lt;chr&gt;, type2 &lt;chr&gt;, ref2 &lt;chr&gt;, notes_stim &lt;chr&gt;,</span></span>
<span id="cb23-15"><a href="#cb23-15" tabindex="-1"></a><span class="co">#&gt; #   data_name &lt;chr&gt;, nonling &lt;int&gt;, language &lt;chr&gt;,</span></span>
<span id="cb23-16"><a href="#cb23-16" tabindex="-1"></a><span class="co">#&gt; #   notes_lang &lt;chr&gt;, language_glotto &lt;chr&gt;,</span></span>
<span id="cb23-17"><a href="#cb23-17" tabindex="-1"></a><span class="co">#&gt; #   notes_glotto &lt;chr&gt;, population &lt;chr&gt;, notes_var &lt;chr&gt;,</span></span>
<span id="cb23-18"><a href="#cb23-18" tabindex="-1"></a><span class="co">#&gt; #   accuracy &lt;int&gt;, ambiguity &lt;int&gt;, aoa &lt;int&gt;, …</span></span>
<span id="cb23-19"><a href="#cb23-19" tabindex="-1"></a></span>
<span id="cb23-20"><a href="#cb23-20" tabindex="-1"></a><span class="co"># import_lab() also loads this dataset </span></span>
<span id="cb23-21"><a href="#cb23-21" tabindex="-1"></a></span>
<span id="cb23-22"><a href="#cb23-22" tabindex="-1"></a><span class="co"># ?labData # use this to learn about the dataset </span></span></code></pre></div>
</div>
<div id="load-filtered-metadata" class="section level3">
<h3>Load Filtered Metadata</h3>
<p>If you want to find specific types of LAB data, you can use the
<code>language</code> and/or <code>variables</code>.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a>saved <span class="ot">&lt;-</span> <span class="fu">import_lab</span>(<span class="at">language =</span> <span class="st">&quot;English&quot;</span>, <span class="at">variables =</span> <span class="fu">c</span>(<span class="st">&quot;aoa&quot;</span>, <span class="st">&quot;freq&quot;</span>))</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a><span class="co"># possible datasets that are English, aoa, and frequency</span></span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">tibble</span>(saved))</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 1</span></span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a><span class="co">#&gt;   saved        </span></span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a><span class="co">#&gt;   &lt;named list&gt; </span></span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a><span class="co">#&gt; 1 &lt;df [3 × 74]&gt;</span></span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" tabindex="-1"></a>saved <span class="ot">&lt;-</span> <span class="fu">import_lab</span>(<span class="at">language =</span> <span class="st">&quot;Spanish&quot;</span>, <span class="at">variables =</span> <span class="fu">c</span>(<span class="st">&quot;aoa&quot;</span>))</span>
<span id="cb24-10"><a href="#cb24-10" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">tibble</span>(saved))</span>
<span id="cb24-12"><a href="#cb24-12" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 × 1</span></span>
<span id="cb24-13"><a href="#cb24-13" tabindex="-1"></a><span class="co">#&gt;   saved        </span></span>
<span id="cb24-14"><a href="#cb24-14" tabindex="-1"></a><span class="co">#&gt;   &lt;named list&gt; </span></span>
<span id="cb24-15"><a href="#cb24-15" tabindex="-1"></a><span class="co">#&gt; 1 &lt;df [8 × 74]&gt;</span></span></code></pre></div>
</div>
<div id="load-specific-data" class="section level3">
<h3>Load Specific Data</h3>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a>es_aos <span class="ot">&lt;-</span> <span class="fu">import_lab</span>(<span class="at">bibtexID =</span> <span class="st">&quot;Alonso2015&quot;</span>, <span class="at">citation =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>es_aos<span class="sc">$</span>citation</span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Alonso, Fernandez, &amp; Diez. (2014). Subjective age-of-acquisition norms for 7039 Spanish words. Behavior Research Methods, 47, 268--274. doi: 10.3758/s13428-014-0454-2&quot;</span></span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">tibble</span>(es_aos<span class="sc">$</span>loaded_data))</span>
<span id="cb26-5"><a href="#cb26-5" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 × 13</span></span>
<span id="cb26-6"><a href="#cb26-6" tabindex="-1"></a><span class="co">#&gt;   word_spanish aoa_M aoa_SD aoa_min aoa_max aoa_zscore</span></span>
<span id="cb26-7"><a href="#cb26-7" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;   &lt;int&gt;   &lt;int&gt;      &lt;dbl&gt;</span></span>
<span id="cb26-8"><a href="#cb26-8" tabindex="-1"></a><span class="co">#&gt; 1 a             2.28   1.44       1       6     -1.65 </span></span>
<span id="cb26-9"><a href="#cb26-9" tabindex="-1"></a><span class="co">#&gt; 2 abajo         2.96   1.37       1       6     -1.36 </span></span>
<span id="cb26-10"><a href="#cb26-10" tabindex="-1"></a><span class="co">#&gt; 3 abandonado    6.06   1.66       2      10     -0.584</span></span>
<span id="cb26-11"><a href="#cb26-11" tabindex="-1"></a><span class="co">#&gt; 4 abandonar     7.58   1.66       4      11     -0.02 </span></span>
<span id="cb26-12"><a href="#cb26-12" tabindex="-1"></a><span class="co">#&gt; 5 abandono      7.22   1.94       3      11      0.04 </span></span>
<span id="cb26-13"><a href="#cb26-13" tabindex="-1"></a><span class="co">#&gt; 6 abatimiento  10.0    1.49       5      11      1.06 </span></span>
<span id="cb26-14"><a href="#cb26-14" tabindex="-1"></a><span class="co">#&gt; # ℹ 7 more variables: oral_freq_log_M &lt;dbl&gt;,</span></span>
<span id="cb26-15"><a href="#cb26-15" tabindex="-1"></a><span class="co">#&gt; #   written_freq_log_SUBTLEXESP_M &lt;dbl&gt;,</span></span>
<span id="cb26-16"><a href="#cb26-16" tabindex="-1"></a><span class="co">#&gt; #   written_freq_log_LEXESP_M &lt;dbl&gt;,</span></span>
<span id="cb26-17"><a href="#cb26-17" tabindex="-1"></a><span class="co">#&gt; #   written_freq_log_espal_M &lt;dbl&gt;, lem_cat_espl_max &lt;chr&gt;,</span></span>
<span id="cb26-18"><a href="#cb26-18" tabindex="-1"></a><span class="co">#&gt; #   lem_max_code &lt;chr&gt;, syllable_N &lt;int&gt;</span></span></code></pre></div>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a>es_sim <span class="ot">&lt;-</span> <span class="fu">import_lab</span>(<span class="at">bibtexID =</span> <span class="st">&quot;Cabana2024_R1&quot;</span>, <span class="at">citation =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a>es_sim<span class="sc">$</span>citation</span>
<span id="cb28-2"><a href="#cb28-2" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Cabana, Zugarramurdi, Valle-Lisboa, &amp; De Deyne. (2024). The \xd2Small World of Words\xd3 free association norms for Rioplatense Spanish. Behavior Research Methods, 56, 968--985. doi: 10.3758/s13428-023-02070-z&quot;</span></span>
<span id="cb28-3"><a href="#cb28-3" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">tibble</span>(es_sim<span class="sc">$</span>loaded_data))</span>
<span id="cb28-5"><a href="#cb28-5" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 × 5</span></span>
<span id="cb28-6"><a href="#cb28-6" tabindex="-1"></a><span class="co">#&gt;   cue   response         R1     N R1.Strength</span></span>
<span id="cb28-7"><a href="#cb28-7" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt; &lt;chr&gt;         &lt;int&gt; &lt;int&gt;       &lt;dbl&gt;</span></span>
<span id="cb28-8"><a href="#cb28-8" tabindex="-1"></a><span class="co">#&gt; 1 ?     pregunta         26    66      0.394 </span></span>
<span id="cb28-9"><a href="#cb28-9" tabindex="-1"></a><span class="co">#&gt; 2 ?     que               8    66      0.121 </span></span>
<span id="cb28-10"><a href="#cb28-10" tabindex="-1"></a><span class="co">#&gt; 3 ?     duda              6    66      0.0909</span></span>
<span id="cb28-11"><a href="#cb28-11" tabindex="-1"></a><span class="co">#&gt; 4 ?     incógnita         4    66      0.0606</span></span>
<span id="cb28-12"><a href="#cb28-12" tabindex="-1"></a><span class="co">#&gt; 5 ?     interrogación     3    66      0.0455</span></span>
<span id="cb28-13"><a href="#cb28-13" tabindex="-1"></a><span class="co">#&gt; 6 ?     no sé             2    66      0.0303</span></span></code></pre></div>
</div>
<div id="match-to-prime-data" class="section level3">
<h3>Match To Prime Data</h3>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a>es_words_merged <span class="ot">&lt;-</span> es_words <span class="sc">%&gt;%</span></span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a>  <span class="co"># merge with the cue word (will be .x variables)</span></span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a>  <span class="fu">left_join</span>(es_aos<span class="sc">$</span>loaded_data, </span>
<span id="cb29-4"><a href="#cb29-4" tabindex="-1"></a>            <span class="at">by =</span> <span class="fu">c</span>(<span class="st">&quot;es_cue&quot;</span> <span class="ot">=</span> <span class="st">&quot;word_spanish&quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb29-5"><a href="#cb29-5" tabindex="-1"></a>  <span class="co"># merge with the target word (will be .y variables)</span></span>
<span id="cb29-6"><a href="#cb29-6" tabindex="-1"></a>  <span class="fu">left_join</span>(es_aos<span class="sc">$</span>loaded_data, </span>
<span id="cb29-7"><a href="#cb29-7" tabindex="-1"></a>            <span class="at">by =</span> <span class="fu">c</span>(<span class="st">&quot;es_target&quot;</span> <span class="ot">=</span> <span class="st">&quot;word_spanish&quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb29-8"><a href="#cb29-8" tabindex="-1"></a>  <span class="co"># merge with free association similarity</span></span>
<span id="cb29-9"><a href="#cb29-9" tabindex="-1"></a>  <span class="fu">left_join</span>(es_sim<span class="sc">$</span>loaded_data, </span>
<span id="cb29-10"><a href="#cb29-10" tabindex="-1"></a>            <span class="at">by =</span> <span class="fu">c</span>(<span class="st">&quot;es_cue&quot;</span> <span class="ot">=</span> <span class="st">&quot;cue&quot;</span>,</span>
<span id="cb29-11"><a href="#cb29-11" tabindex="-1"></a>                   <span class="st">&quot;es_target&quot;</span> <span class="ot">=</span> <span class="st">&quot;response&quot;</span>))</span>
<span id="cb29-12"><a href="#cb29-12" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">tibble</span>(es_words_merged))</span>
<span id="cb29-14"><a href="#cb29-14" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 × 33</span></span>
<span id="cb29-15"><a href="#cb29-15" tabindex="-1"></a><span class="co">#&gt;   es_cue   es_target type    cue_type target_type es_cosine</span></span>
<span id="cb29-16"><a href="#cb29-16" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;           &lt;dbl&gt;</span></span>
<span id="cb29-17"><a href="#cb29-17" tabindex="-1"></a><span class="co">#&gt; 1 lenguado abadejo   related word     word            0.571</span></span>
<span id="cb29-18"><a href="#cb29-18" tabindex="-1"></a><span class="co">#&gt; 2 dejar    abandonar related word     word            0.542</span></span>
<span id="cb29-19"><a href="#cb29-19" tabindex="-1"></a><span class="co">#&gt; 3 espalda  abdomen   related word     word            0.425</span></span>
<span id="cb29-20"><a href="#cb29-20" tabindex="-1"></a><span class="co">#&gt; 4 beso     abrazo    related word     word            0.753</span></span>
<span id="cb29-21"><a href="#cb29-21" tabindex="-1"></a><span class="co">#&gt; 5 ridículo absurdo   related word     word            0.704</span></span>
<span id="cb29-22"><a href="#cb29-22" tabindex="-1"></a><span class="co">#&gt; 6 abuelo   abuela    related word     word            0.745</span></span>
<span id="cb29-23"><a href="#cb29-23" tabindex="-1"></a><span class="co">#&gt; # ℹ 27 more variables: aoa_M.x &lt;dbl&gt;, aoa_SD.x &lt;dbl&gt;,</span></span>
<span id="cb29-24"><a href="#cb29-24" tabindex="-1"></a><span class="co">#&gt; #   aoa_min.x &lt;int&gt;, aoa_max.x &lt;int&gt;, aoa_zscore.x &lt;dbl&gt;,</span></span>
<span id="cb29-25"><a href="#cb29-25" tabindex="-1"></a><span class="co">#&gt; #   oral_freq_log_M.x &lt;dbl&gt;,</span></span>
<span id="cb29-26"><a href="#cb29-26" tabindex="-1"></a><span class="co">#&gt; #   written_freq_log_SUBTLEXESP_M.x &lt;dbl&gt;,</span></span>
<span id="cb29-27"><a href="#cb29-27" tabindex="-1"></a><span class="co">#&gt; #   written_freq_log_LEXESP_M.x &lt;dbl&gt;,</span></span>
<span id="cb29-28"><a href="#cb29-28" tabindex="-1"></a><span class="co">#&gt; #   written_freq_log_espal_M.x &lt;dbl&gt;,</span></span>
<span id="cb29-29"><a href="#cb29-29" tabindex="-1"></a><span class="co">#&gt; #   lem_cat_espl_max.x &lt;chr&gt;, lem_max_code.x &lt;chr&gt;, …</span></span></code></pre></div>
</div>
</div>
<div id="other-cool-stuff" class="section level2">
<h2>Other Cool Stuff</h2>
<p>We used <code>labjs</code> for this project. The datasets you get
from <code>labjs</code> are in a SQLite file. It’s not super fun to
process. So, they wrote a function to do that. We included that function
here as <code>processData()</code>, and you can see that we used it in
our data processing files. It’s here if you want to use it yourself on
<code>labjs</code> projects.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">processData</span>(<span class="st">&quot;data.sqlite&quot;</span>)</span></code></pre></div>
<ul>
<li>Check out the <code>text</code> package for how to merge word
embeddings in <em>R</em>: <a href="https://osf.io/preprints/psyarxiv/293kt" class="uri">https://osf.io/preprints/psyarxiv/293kt</a></li>
<li><a href="https://cran.r-project.org/web/packages/text/vignettes/huggingface_in_r.html" class="uri">https://cran.r-project.org/web/packages/text/vignettes/huggingface_in_r.html</a></li>
</ul>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
